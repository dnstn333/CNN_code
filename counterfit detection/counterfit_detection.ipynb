{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. data preprocessing 및 dataset 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "20\n",
      "14 + 3 + 3 = 20\n",
      "A\n",
      "(14, 64, 304, 5)\n",
      "(14, 2)\n",
      "(3, 64, 304, 5)\n",
      "(3, 2)\n",
      "B\n",
      "(14, 64, 304, 5)\n",
      "(14, 2)\n",
      "(3, 64, 304, 5)\n",
      "(3, 2)\n",
      "C\n",
      "(14, 64, 304, 5)\n",
      "(14, 2)\n",
      "(3, 64, 304, 5)\n",
      "(3, 2)\n",
      "D\n",
      "(14, 64, 304, 5)\n",
      "(14, 2)\n",
      "(3, 64, 304, 5)\n",
      "(3, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import cv2\n",
    "# show error cases\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "\n",
    "num_classes = 2\n",
    "dataset_dir = \"../dataset\"\n",
    "channelName_list = [\"BLUE\", \"GREEN\", \"IRR\", \"IRT\", \"RED\"]\n",
    "headingName_list = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "def shuffle_data(data, label):\n",
    "    if len(data) % 4 != 0:\n",
    "        print(\"dataNum ERR!!!\")\n",
    "        return data, label, NULL\n",
    "    \n",
    "    halfLen = int(len(data)/2)\n",
    "    quarLen = int(halfLen/2)\n",
    "    \n",
    "    idx = np.arange(halfLen)\n",
    "    #print(\"S_\" + str(idx))\n",
    "    \n",
    "    for num in idx:\n",
    "        if num >= quarLen:\n",
    "            idx[np.where(idx == num)] = quarLen + num\n",
    "    \n",
    "    #print(\"1_\" + str(idx))\n",
    "    np.random.shuffle(idx)\n",
    "    #print(\"2_\" + str(idx))\n",
    "\n",
    "    tmpidx = [quarLen + num for num in idx]\n",
    "    idx = np.concatenate((idx, tmpidx))\n",
    "    #print(\"3_\" + str(idx))\n",
    "    shuffled_data = np.array(data)[np.array(idx)]\n",
    "    shuffled_label = np.array(label)[np.array(idx)]\n",
    "    #print(\"E_\" + str(idx))\n",
    "   \n",
    "    return shuffled_data, shuffled_label, idx #result_idx\n",
    "    \n",
    "def load_data(parent_dir, ext):\n",
    "    image_A_list = []\n",
    "    image_B_list = []\n",
    "    image_C_list = []\n",
    "    image_D_list = []\n",
    "    label_A_list = []\n",
    "    label_B_list = []\n",
    "    label_C_list = []\n",
    "    label_D_list = []\n",
    "    \n",
    "    image_Dic = {'A' : image_A_list, 'B' : image_B_list, 'C' : image_C_list, 'D' : image_D_list}\n",
    "    label_Dic = {'A' : label_A_list, 'B' : label_B_list, 'C' : label_C_list, 'D' : label_D_list}\n",
    "    filePath_list = []\n",
    "    \n",
    "    labelNames = os.listdir(parent_dir)\n",
    "    for labelName in labelNames: # 하위 디렉토리 탐색      (label 폴더 : 0, 1)\n",
    "        labelDirPath = os.path.join(parent_dir, labelName)\n",
    "        print(labelName)\n",
    "        if os.path.isdir(labelDirPath): # 디렉토리인 경우\n",
    "            headingNames = os.listdir(labelDirPath)\n",
    "            for headingName in headingNames: # 하위 디렉토리 탐색      (heading 폴더 : A, B, C, D)\n",
    "                if not(any(headingName in tmpstr for tmpstr in headingName_list)):\n",
    "                    print(\"head ERR!!!\")\n",
    "                    continue  # 해당 폴더가 투입면 폴더가 아닌 경우 다시 검색\n",
    "                #print('_' + headingName)\n",
    "                headingDirPath = os.path.join(labelDirPath, headingName)\n",
    "\n",
    "                if os.path.isdir(headingDirPath): # 디렉토리인 경우\n",
    "                    channelNames = os.listdir(headingDirPath)\n",
    "                    \n",
    "                    #로드 리스트 생성\n",
    "                    loadingImg_list = []\n",
    "                    loadinglable_list = []\n",
    "                    loadingName_list = []\n",
    "                    \n",
    "                    for channelName in channelNames:  # 하위 디렉토리 탐색      (각 Channel 접근 : R, G, B, IRR, IRT)\n",
    "                        if not(any(channelName in tmpstr for tmpstr in channelName_list)):\n",
    "                            print(\"channel ERR!!!\")\n",
    "                            continue  # 해당 폴더가 채널폴더가 아닌 경우 다시 검색\n",
    "                        #print('__' + channelName)\n",
    "                        fileDirPath = os.path.join(headingDirPath, channelName)\n",
    "                        \n",
    "                        if os.path.isdir(fileDirPath): # 디렉토리인 경우\n",
    "                            fileNames = os.listdir(fileDirPath)\n",
    "                            for fileName in fileNames: #해당폴더 전체 이미지 탐색\n",
    "                                # 순서대로 새로운 채널에 입력\n",
    "                                filePath = os.path.join(fileDirPath, fileName)\n",
    "\n",
    "                                _ext = os.path.splitext(filePath)[-1] # 파일 확장자 확인\n",
    "                                if _ext == ext:\n",
    "                                    image = mpimg.imread(filePath)\n",
    "                                    if image is None:\n",
    "                                        continue\n",
    "                                \n",
    "                                #이미지 크기 정규화\n",
    "                                image = image.astype(np.float32) / 255.\n",
    "                                #image = image.reshape(65, 308)\n",
    "                                \n",
    "                                #있는지 확인\n",
    "                                if any(fileName in tmpstr for tmpstr in loadingName_list): #파일이 있는지 없는지 확인\n",
    "                                    #있으면 dstack\n",
    "                                    tmpidx = loadingName_list.index(fileName)\n",
    "                                    shapetmp = loadingImg_list[tmpidx].shape\n",
    "                                    loadingImg_list[tmpidx] = np.dstack((loadingImg_list[tmpidx], image))\n",
    "                                    \n",
    "                                    if channelName == \"IRT\":\n",
    "                                        nameListLen = int(len(loadingName_list)/2 -1)\n",
    "                                        #print(type(nameListLen))\n",
    "                                        #print(loadingName_list)\n",
    "                                        for chatchName in loadingName_list[nameListLen:] :\n",
    "                                            if fileName[5:] in chatchName:\n",
    "                                                findedName = chatchName\n",
    "                                        tmp = loadingName_list.index(findedName)\n",
    "                                        loadingImg_list[tmp] = np.dstack((loadingImg_list[tmp], image))\n",
    "                                    \n",
    "                                    #if tmp == 0:\n",
    "                                    #print(\"!\" + fileName + \"\\t\" + str(tmp) + \"\\t\" + str(len(loadingImg_list)) + \"\\t\" +  str(image.shape) + \"\\t\" +  str(shapetmp) + \"\\t\" +  str(loadingImg_list[tmp].shape))\n",
    "                                else:\n",
    "                                    #없으면 append\n",
    "                                    loadingImg_list.append(image)\n",
    "                                    #label & name 추가\n",
    "                                    #loadinglable_list.append(str(len(loadingName_list))+\"\\t\"+labelName + headingName + fileName)\n",
    "                                    loadinglable_list.append(labelName)\n",
    "                                    loadingName_list.append(fileName)\n",
    "                                    #print(\"?\" + fileName)\n",
    "\n",
    "                    #리스트에 로드된 애들 입력\n",
    "                    if labelName == '1':\n",
    "                        image_Dic[headingName] = image_Dic[headingName] + loadingImg_list\n",
    "                        label_Dic[headingName] = label_Dic[headingName] + loadinglable_list\n",
    "                    else:\n",
    "                        image_Dic[headingName] = loadingImg_list\n",
    "                        label_Dic[headingName] = loadinglable_list\n",
    "                    for i in range(len(loadingName_list)):\n",
    "                        filePath_list.append(os.path.join(headingName, loadingName_list[i]))\n",
    "                    #print(len(image_Dic[headingName]))\n",
    "\n",
    "    return image_Dic, label_Dic, filePath_list\n",
    "\n",
    "\n",
    "# data 불러오기\n",
    "image_Dic, label_Dic, filepath_list = load_data(dataset_dir, '.bmp')\n",
    "\n",
    "# heading 종류 마다 개수 확인\n",
    "data_len = len(label_Dic['A'])\n",
    "for heading in headingName_list:\n",
    "    if data_len != len(label_Dic[heading]):\n",
    "        print(\"DataSize ERR!!!\")\n",
    "        exit()\n",
    "\n",
    "# dataset 분할\n",
    "train_size = int(0.7 * data_len)\n",
    "valid_size = int(0.15 * data_len)\n",
    "test_size = data_len - train_size - valid_size\n",
    "print(data_len)\n",
    "print(train_size, '+', valid_size, '+', test_size, '=', train_size+valid_size+test_size)\n",
    "\n",
    "# data shuffling\n",
    "shuffled_image_Dic = {}\n",
    "shuffled_label_Dic = {}\n",
    "shuffled_idx_Dic  = {}\n",
    "\n",
    "for heading in headingName_list:\n",
    "    shuffled_image_Dic[heading], shuffled_label_Dic[heading], shuffled_idx_Dic[heading] = shuffle_data(image_Dic[heading], label_Dic[heading])\n",
    "\n",
    "# one-hot vector로 변환\n",
    "for heading in headingName_list:\n",
    "    shuffled_label_Dic[heading] = np_utils.to_categorical(shuffled_label_Dic[heading], num_classes)\n",
    "\n",
    "x_train_Dic = {}\n",
    "y_train_Dic = {}\n",
    "x_valid_Dic = {}\n",
    "y_valid_Dic = {}\n",
    "x_test_Dic = {}\n",
    "y_test_Dic = {}\n",
    "shuffle_indices_Dic = {} # 디버그용\n",
    "    \n",
    "# dataset 구축\n",
    "for heading in headingName_list:\n",
    "    x_train_Dic[heading] = shuffled_image_Dic[heading][:train_size]\n",
    "    y_train_Dic[heading] = shuffled_label_Dic[heading][:train_size]\n",
    "    x_valid_Dic[heading] = shuffled_image_Dic[heading][train_size:data_len-test_size]\n",
    "    y_valid_Dic[heading] = shuffled_label_Dic[heading][train_size:data_len-test_size]\n",
    "    x_test_Dic[heading] = shuffled_image_Dic[heading][data_len-test_size:]\n",
    "    y_test_Dic[heading] = shuffled_label_Dic[heading][data_len-test_size:]\n",
    "    shuffle_indices_Dic = shuffled_idx_Dic[heading][data_len-test_size:] # 디버그용\n",
    "    print(heading)\n",
    "    print(x_train_Dic[heading].shape)\n",
    "    print(y_train_Dic[heading].shape)\n",
    "    print(x_test_Dic[heading].shape)\n",
    "    print(y_test_Dic[heading].shape)\n",
    "\n",
    "\"\"\"\n",
    "print(len(image_Dic['A']))\n",
    "print(image_Dic['A'][0].shape)\n",
    "#print(image_Dic['A'])\n",
    "#img = image_Dic['A'][0].reshape(325, 308, 1)\n",
    "img = np.zeros((64, 304))\n",
    "#print(img.shape)\n",
    "#for i in range(len(filepath_list)):\n",
    "#    print(filepath_list[i])\n",
    "\n",
    "\n",
    "for chan in range(5):\n",
    "    for i in range(64):\n",
    "        for j in range(304):\n",
    "            img[i][j] = image_Dic['A'][5][i][j][chan]\n",
    "    plt.gray()\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "print()\n",
    "for head in headingName_list:\n",
    "    print(head)\n",
    "    for imgSize in range(len(shuffled_label_Dic['A'])):\n",
    "        print(str(int(shuffled_idx_Dic[head][imgSize])%5) + \"\\t\" + str(shuffled_idx_Dic[head][imgSize]) + \"\\t\" + str(shuffled_label_Dic[head][imgSize]))\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Activation\n",
    "from keras.models import Sequential, save_model\n",
    "\n",
    "\n",
    "for heading in headingName_list:\n",
    "    path_heading_str = \"/\" + heading + \"/\"\n",
    "    projectName_str = \"1_full\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters= 16, kernel_size = (3,3), activation='relu', padding='valid', input_shape= x_train.shape[1:]))\n",
    "    model.add(Conv2D(filters= 16, kernel_size = (3,3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(pool_size= (4, 4)))\n",
    "\n",
    "    model.add(Conv2D(filters= 32, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "    #model.add(Conv2D(filters= 32, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size= (4, 4)))\n",
    "    \n",
    "    model.add(Conv2D(filters= 32, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "    #model.add(Conv2D(filters= 32, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size= (4, 4)))\n",
    "    \n",
    "    model.add(Conv2D(filters= 32, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "    #model.add(Conv2D(filters= 32, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size= (4, 4)))\n",
    "\n",
    "    model.add(Conv2D(filters= 32, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters= 32, kernel_size = (3,3), activation='relu', padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # configure the model\n",
    "    model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # prints a summary representation of the model\n",
    "    model.summary()\n",
    "\n",
    "    # set tensorboard\n",
    "    from keras.callbacks import TensorBoard\n",
    "    tbCallback = TensorBoard(log_dir='./tensorboard/' + path_heading_str + projectName_str)\n",
    "    tbCallback.set_model(model)\n",
    "\n",
    "    # save the model\n",
    "    save_model(model, './logs/' + path_heading_str + 'my_model_' + projectName_str + '.hdf5')\n",
    "\n",
    "    # make parameters checkpoint\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    checkpoint = ModelCheckpoint(filepath=\"./logs/\" + path_heading_str + \"weights.best_\" + projectName_str + \".hdf5\", verbose=1, \n",
    "                                   monitor='loss', save_best_only=True, mode='auto')\n",
    "\n",
    "    # # set early stopping\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "\n",
    "    # train the model\n",
    "    model.fit(x_train, y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=256,\n",
    "                    shuffle=False, # previously shuffled\n",
    "                    validation_data=(x_valid, y_valid),\n",
    "                    callbacks = [tbCallback, checkpoint, early_stopping])\n",
    "\n",
    "    '''\n",
    "    learning is done at this point\n",
    "    '''\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    print('Test loss: ', score[0])\n",
    "    print('Test accuracy: ', score[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
